{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Different Machine Learning Models\n",
    "\n",
    "## Models Tried\n",
    "\n",
    "1. RandomForestRegressor\n",
    "    - Advantages: Why did we start with this? \n",
    "    - Drawbacks: Why did we pivot away?\n",
    "1. K Nearest Neighbors\n",
    "    - Advantages: Why was this the next choice?\n",
    "    - Drawbacks: Why did we pivot away?\n",
    "1. Gradient Boosting Classifier\n",
    "    - Advantages: Why was this the next choice?\n",
    "    - Drawbacks: Why did we pivot away?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Scores\n",
      "\tAbove Treeline\n",
      "\t\tPrediction (Training) R2 score:\t 0.86\n",
      "\t\tActual (Validation) R2 score:\t 0.23\n",
      "\t\tPrediction (Training) MAE:   0.1748908279220779\n",
      "\t\tPrediction (Validation) MAE: 0.499442482611022\n",
      "\n",
      "\t\tPrediction (Training) R2 score (rounded): 0.89\n",
      "\t\tActual (Validation) R2 score (rounded):   0.02\n",
      "\t\tPrediction (Training) MAE (rounded):\t 0.03977272727272727\n",
      "\t\tPrediction (Validation) MAE (rounded):\t 0.449438202247191\n",
      "\n",
      "\t\tPrediction Variance (with rounding)\n",
      "\t\t\tPredicted less dangerous: 6.58%\n",
      "\t\t\tPredicted more dangerous: 5.22%\n",
      "\t\t\tWAY off: 0.23%\n",
      "\t\t  Calculated Score: 87.98%\n",
      "\tAt Treeline\n",
      "\t\tPrediction (Training) R2 score:\t 0.87\n",
      "\t\tActual (Validation) R2 score:\t 0.22\n",
      "\t\tPrediction (Training) MAE:   0.1914916801948052\n",
      "\t\tPrediction (Validation) MAE: 0.5415973782771535\n",
      "\n",
      "\t\tPrediction (Training) R2 score (rounded): 0.90\n",
      "\t\tActual (Validation) R2 score (rounded):   -0.02\n",
      "\t\tPrediction (Training) MAE (rounded):\t 0.045454545454545456\n",
      "\t\tPrediction (Validation) MAE (rounded):\t 0.5393258426966292\n",
      "\n",
      "\t\tPrediction Variance (with rounding)\n",
      "\t\t\tPredicted less dangerous: 6.80%\n",
      "\t\t\tPredicted more dangerous: 6.80%\n",
      "\t\t\tWAY off: 0.45%\n",
      "\t\t  Calculated Score: 85.94%\n",
      "\tBelow Treeline\n",
      "\t\tPrediction (Training) R2 score:\t 0.86\n",
      "\t\tActual (Validation) R2 score:\t 0.06\n",
      "\t\tPrediction (Training) MAE:   0.20889454816017317\n",
      "\t\tPrediction (Validation) MAE: 0.54734430176565\n",
      "\n",
      "\t\tPrediction (Training) R2 score (rounded): 0.88\n",
      "\t\tActual (Validation) R2 score (rounded):   -0.04\n",
      "\t\tPrediction (Training) MAE (rounded):\t 0.05965909090909091\n",
      "\t\tPrediction (Validation) MAE (rounded):\t 0.4606741573033708\n",
      "\n",
      "\t\tPrediction Variance (with rounding)\n",
      "\t\t\tPredicted less dangerous: 7.48%\n",
      "\t\t\tPredicted more dangerous: 5.67%\n",
      "\t\t\tWAY off: 0.45%\n",
      "\t\t  Calculated Score: 86.39%\n"
     ]
    }
   ],
   "source": [
    "def random_forest_prediction():\n",
    "    # --- Load Data ---\n",
    "    import pandas as pd\n",
    "    ESN = pd.read_csv('../content/csv/FINALDATASET_EastSlopesNorth.csv')\n",
    "    WSN = pd.read_csv('../content/csv/FINALDATASET_WestSlopesNorth.csv')\n",
    "    WSS = pd.read_csv('../content/csv/FINALDATASET_WestSlopesSouth.csv')\n",
    "    assert all(ESN.columns) == all(WSN.columns) and all(ESN.columns) == all(WSS.columns), \\\n",
    "        'All dataframes should have the same columns'        \n",
    "    # Combine dataframes\n",
    "    DATA = pd.concat([ESN, WSN, WSS], axis=0, ignore_index=True)\n",
    "    # Show any rows with NaN\n",
    "    DATA[DATA.isna().any(axis=1)]\n",
    "    # Todo: try dropping NaN columns instead\n",
    "    DATA.fillna(DATA.mean(numeric_only=True), inplace=True)\n",
    "    # Todo: should we try to use these?\n",
    "    DATA.drop(['Date', 'Area'], axis=1, inplace=True)\n",
    "    # Can uncomment to make prediction better\n",
    "    DATA.drop(\n",
    "        ['Yesterday Danger Above Treeline', \n",
    "         'Yesterday Danger At Treeline', \n",
    "         'Yesterday Danger Below Treeline'], axis=1, inplace=True)\n",
    "    # --- Done Loading Data ---\n",
    "\n",
    "    # --- Train Model ---\n",
    "    def make_prediction_rfr(df, y_col):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "        # Separate columns \n",
    "        x = df.drop(y_col, axis=1)\n",
    "        y = df[y_col]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)\n",
    "\n",
    "        rf_regressor = RandomForestRegressor(random_state=42)\n",
    "        rf_regressor.fit(x_train, y_train)\n",
    "\n",
    "        y_pred_train = rf_regressor.predict(x_train)\n",
    "        y_pred_test = rf_regressor.predict(x_test) \n",
    "\n",
    "        print('\\t' + y_col)\n",
    "        print('\\t\\tPrediction (Training) R2 score:\\t', '{0:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "        print('\\t\\tActual (Validation) R2 score:\\t', '{0:.2f}'.format(r2_score(y_test, y_pred_test)))\n",
    "        print('\\t\\tPrediction (Training) MAE:  ', mean_absolute_error(y_train, y_pred_train))\n",
    "        print('\\t\\tPrediction (Validation) MAE:', mean_absolute_error(y_test, y_pred_test))\n",
    "        print()\n",
    "        print('\\t\\tPrediction (Training) R2 score (rounded):', '{0:.2f}'.format(r2_score(y_train, [round(y) for y in y_pred_train])))\n",
    "        print('\\t\\tActual (Validation) R2 score (rounded):  ', '{0:.2f}'.format(r2_score(y_test, [round(y) for y in y_pred_test])))\n",
    "        print('\\t\\tPrediction (Training) MAE (rounded):\\t', mean_absolute_error(y_train, [round(y) for y in y_pred_train]))\n",
    "        print('\\t\\tPrediction (Validation) MAE (rounded):\\t', mean_absolute_error(y_test, [round(y) for y in y_pred_test]))\n",
    "\n",
    "        # Perform own evaluation\n",
    "        predicted = rf_regressor.predict(x)\n",
    "        actual = y\n",
    "        assert len(predicted) == len(actual)\n",
    "        over_predict = 0\n",
    "        under_predict = 0\n",
    "        way_off = 0\n",
    "        for i in range(len(actual)):\n",
    "            p = round(predicted[i])\n",
    "            a = actual[i]\n",
    "            diff = a - p\n",
    "            if diff == 1:\n",
    "                under_predict += 1\n",
    "            if diff == -1:\n",
    "                over_predict += 1\n",
    "            if diff < -1 or diff > 1:\n",
    "                way_off += 1\n",
    "                # print('WAY off: predicted:', p, 'actual:', a)\n",
    "        total = len(actual)\n",
    "        under_pct = '{0:.2f}'.format(under_predict * 100.0 / total)\n",
    "        over_pct = '{0:.2f}'.format(over_predict * 100.0 / total)\n",
    "        way_pct = '{0:.2f}'.format(way_off * 100.0 / total)\n",
    "        correct_pct = '{0:.2f}'.format(100.0*(total - under_predict - over_predict - way_off) / total)\n",
    "        print('\\n\\t\\tPrediction Variance (with rounding)')\n",
    "        print('\\t\\t\\tPredicted less dangerous:', f'{under_pct}%')\n",
    "        print('\\t\\t\\tPredicted more dangerous:', f'{over_pct}%')\n",
    "        print('\\t\\t\\tWAY off:', f'{way_pct}%')\n",
    "        print('\\t\\t  Calculated Score:', f'{correct_pct}%')\n",
    "\n",
    "    # Drop columms that were determined to hurt the prediction\n",
    "    DATA.drop(['Total Snowfall 24hr', 'Total Snowfall 72hr'], axis=1, inplace=True)\n",
    "\n",
    "    above_treeline = DATA.drop(['At Treeline', 'Below Treeline'], axis=1)\n",
    "    at_treeline = DATA.drop(['Above Treeline', 'Below Treeline'], axis=1)\n",
    "    below_treeline = DATA.drop(['Above Treeline', 'At Treeline'], axis=1)\n",
    "\n",
    "    print('Random Forest Regressor Scores')\n",
    "    make_prediction_rfr(above_treeline, 'Above Treeline')\n",
    "    make_prediction_rfr(at_treeline, 'At Treeline')\n",
    "    make_prediction_rfr(below_treeline, 'Below Treeline')\n",
    "\n",
    "random_forest_prediction()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Neighbors Classifier Scores\n",
      "\tAbove Treeline\n",
      "\t\tPrediction (Training) Score:\t 0.64\n",
      "\t\tActual (Validation) score:\t 0.57\n",
      "\n",
      "\t\tPrediction Variance\n",
      "\t\t\tPredicted less dangerous: 24.72%\n",
      "\t\t\tPredicted more dangerous: 9.07%\n",
      "\t\t\tWAY off: 3.40%\n",
      "\tAt Treeline\n",
      "\t\tPrediction (Training) Score:\t 0.61\n",
      "\t\tActual (Validation) score:\t 0.54\n",
      "\n",
      "\t\tPrediction Variance\n",
      "\t\t\tPredicted less dangerous: 22.45%\n",
      "\t\t\tPredicted more dangerous: 14.97%\n",
      "\t\t\tWAY off: 3.40%\n",
      "\tBelow Treeline\n",
      "\t\tPrediction (Training) Score:\t 0.61\n",
      "\t\tActual (Validation) score:\t 0.58\n",
      "\n",
      "\t\tPrediction Variance\n",
      "\t\t\tPredicted less dangerous: 23.13%\n",
      "\t\t\tPredicted more dangerous: 8.84%\n",
      "\t\t\tWAY off: 7.48%\n"
     ]
    }
   ],
   "source": [
    "def k_neighbors_prediction():\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    ESN = pd.read_csv('../content/csv/FINALDATASET_EastSlopesNorth.csv')\n",
    "    WSN = pd.read_csv('../content/csv/FINALDATASET_WestSlopesNorth.csv')\n",
    "    WSS = pd.read_csv('../content/csv/FINALDATASET_WestSlopesSouth.csv')\n",
    "\n",
    "    assert all(ESN.columns) == all(WSN.columns) and all(ESN.columns) == all(WSS.columns), \\\n",
    "        'All dataframes should have the same columns'\n",
    "        \n",
    "        # Combine dataframes\n",
    "\n",
    "    DATA = pd.concat([ESN, WSN, WSS], axis=0, ignore_index=True)\n",
    "\n",
    "    # Show any rows with NaN\n",
    "    DATA[DATA.isna().any(axis=1)]\n",
    "\n",
    "    # Todo: try dropping NaN columns instead\n",
    "    DATA.fillna(DATA.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Todo: should we try to use these?\n",
    "    DATA.drop(['Date', 'Area'], axis=1, inplace=True)\n",
    "\n",
    "    # Try normalizing: does not help\n",
    "    # for col in DATA.columns:\n",
    "        # DATA[col] = (DATA[col]-DATA[col].mean())/DATA[col].std()\n",
    "    # DATA=(DATA-DATA.min())/(DATA.max()-DATA.min())\n",
    "\n",
    "    # Can uncomment to make prediction better\n",
    "    DATA.drop(['Yesterday Danger Above Treeline', \\\n",
    "            'Yesterday Danger At Treeline', 'Yesterday Danger Below Treeline'], \\\n",
    "                axis=1, inplace=True)\n",
    "\n",
    "    NORMALIZED = DATA.copy(deep=True)\n",
    "    for col in NORMALIZED.columns:\n",
    "        if col not in (\n",
    "            'Above Treeline',\n",
    "            'At Treeline', \n",
    "            'Below Treeline'\n",
    "            'Was High Winds 24hr', \n",
    "            'Was Heavy Snowfall 24hr'):\n",
    "            NORMALIZED[col] = (NORMALIZED[col]-NORMALIZED[col].mean())/NORMALIZED[col].std()\n",
    "\n",
    "    def make_prediction_knn(df, y_col):\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        x = df.drop(y_col, axis=1)\n",
    "        y = df[y_col]\n",
    "\n",
    "        x_training_data, x_test_data, y_training_data, y_test_data = \\\n",
    "            train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=24) \n",
    "\n",
    "        model.fit(x_training_data, y_training_data)\n",
    "\n",
    "        y_pred_train = model.predict(x_training_data)\n",
    "        y_pred = model.predict(x_test_data)\n",
    "\n",
    "        print('\\t' + y_col)\n",
    "        print('\\t\\tPrediction (Training) Score:\\t', '{0:.2f}'.format(\n",
    "            model.score(x_training_data, y_training_data)))\n",
    "        print('\\t\\tActual (Validation) score:\\t', '{0:.2f}'.format(\n",
    "            model.score(x_test_data, y_test_data)))\n",
    "        # print('\\t\\tPrediction (Training) score:\\t', '{0:.2f}'.format(model.score(y_training_data, y_pred_train)))\n",
    "        # print('\\t\\tActual (Validation) score:\\t', '{0:.2f}'.format(model.score(y_test_data, y_pred)))\n",
    "        predicted = model.predict(x)\n",
    "        actual = y\n",
    "        assert len(predicted) == len(actual)\n",
    "        over_predict = 0\n",
    "        under_predict = 0\n",
    "        way_off = 0\n",
    "        for i in range(len(actual)):\n",
    "            p = predicted[i]\n",
    "            a = actual[i]\n",
    "            diff = a - p\n",
    "            if diff == 1:\n",
    "                under_predict += 1\n",
    "            if diff == -1:\n",
    "                over_predict += 1\n",
    "            if diff < -1 or diff > 1:\n",
    "                way_off += 1\n",
    "                # print('WAY off: predicted:', p, 'actual:', a)\n",
    "        under_pct = '{0:.2f}'.format(under_predict * 100.0 / len(actual))\n",
    "        over_pct = '{0:.2f}'.format(over_predict * 100.0 / len(actual))\n",
    "        way_pct = '{0:.2f}'.format(way_off * 100.0 / len(actual))\n",
    "        print('\\n\\t\\tPrediction Variance')\n",
    "        print('\\t\\t\\tPredicted less dangerous:', f'{under_pct}%')\n",
    "        print('\\t\\t\\tPredicted more dangerous:', f'{over_pct}%')\n",
    "        print('\\t\\t\\tWAY off:', f'{way_pct}%')\n",
    "\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    # some value was making it complain\n",
    "    NORMALIZED['Below Treeline'] = preprocessing.LabelEncoder().fit_transform(NORMALIZED['Below Treeline'])\n",
    "\n",
    "    above_treeline = NORMALIZED.drop(['At Treeline', 'Below Treeline'], axis=1)\n",
    "    at_treeline = NORMALIZED.drop(['Above Treeline', 'Below Treeline'], axis=1)\n",
    "    below_treeline = NORMALIZED.drop(['Above Treeline', 'At Treeline'], axis=1)\n",
    "\n",
    "    print('K Neighbors Classifier Scores')\n",
    "    make_prediction_knn(above_treeline, 'Above Treeline')\n",
    "    make_prediction_knn(at_treeline, 'At Treeline')\n",
    "    make_prediction_knn(below_treeline, 'Below Treeline')\n",
    "\n",
    "k_neighbors_prediction()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Scores\n",
      "\tAbove Treeline\n",
      "\t\tPrediction (Training) Score:\t0.59\n",
      "\t\tActual (Validation) Score:\t0.64\n",
      "\n",
      "\t\tPrediction Variance\n",
      "\t\t\tPredicted less dangerous: 31.29%\n",
      "\t\t\tPredicted more dangerous: 4.76%\n",
      "\t\t\tWAY off: 3.85%\n",
      "\tAt Treeline\n",
      "\t\tPrediction (Training) Score:\t0.58\n",
      "\t\tActual (Validation) Score:\t0.62\n",
      "\n",
      "\t\tPrediction Variance\n",
      "\t\t\tPredicted less dangerous: 23.58%\n",
      "\t\t\tPredicted more dangerous: 14.29%\n",
      "\t\t\tWAY off: 3.40%\n",
      "\tBelow Treeline\n",
      "\t\tPrediction (Training) Score:\t0.54\n",
      "\t\tActual (Validation) Score:\t0.58\n",
      "\n",
      "\t\tPrediction Variance\n",
      "\t\t\tPredicted less dangerous: 32.20%\n",
      "\t\t\tPredicted more dangerous: 0.91%\n",
      "\t\t\tWAY off: 11.79%\n"
     ]
    }
   ],
   "source": [
    "def gradient_boosting_prediction():\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    ESN = pd.read_csv('../content/csv/FINALDATASET_EastSlopesNorth.csv')\n",
    "    WSN = pd.read_csv('../content/csv/FINALDATASET_WestSlopesNorth.csv')\n",
    "    WSS = pd.read_csv('../content/csv/FINALDATASET_WestSlopesSouth.csv')\n",
    "\n",
    "    assert all(ESN.columns) == all(WSN.columns) and all(ESN.columns) == all(WSS.columns), \\\n",
    "        'All dataframes should have the same columns'\n",
    "        \n",
    "        # Combine dataframes\n",
    "\n",
    "    DATA = pd.concat([ESN, WSN, WSS], axis=0, ignore_index=True)\n",
    "\n",
    "    # Show any rows with NaN\n",
    "    DATA[DATA.isna().any(axis=1)]\n",
    "\n",
    "    # Todo: try dropping NaN columns instead\n",
    "    DATA.fillna(DATA.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Todo: should we try to use these?\n",
    "    DATA.drop(['Date', 'Area'], axis=1, inplace=True)\n",
    "\n",
    "    # Try normalizing: does not help\n",
    "    # for col in DATA.columns:\n",
    "        # DATA[col] = (DATA[col]-DATA[col].mean())/DATA[col].std()\n",
    "    # DATA=(DATA-DATA.min())/(DATA.max()-DATA.min())\n",
    "\n",
    "    # Can uncomment to make prediction better\n",
    "    DATA.drop(['Yesterday Danger Above Treeline', \\\n",
    "            'Yesterday Danger At Treeline', 'Yesterday Danger Below Treeline'], \\\n",
    "                axis=1, inplace=True)\n",
    "    \n",
    "    def make_prediction_grad(df, y_col):\n",
    "\n",
    "        from sklearn.model_selection import KFold\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "        X, y = df.drop(y_col, axis=1), df[y_col]\n",
    "\n",
    "        kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "        for train_index,val_index in kf.split(X):\n",
    "            X_train,X_val = X.iloc[train_index],X.iloc[val_index],\n",
    "            y_train,y_val = y.iloc[train_index],y.iloc[val_index],\n",
    "\n",
    "        gb_clf = GradientBoostingClassifier(n_estimators=5, learning_rate=0.05, max_features=2, max_depth=2, random_state=42)\n",
    "        gb_clf.fit(X_train, y_train)\n",
    "\n",
    "        print('\\t' + y_col)\n",
    "        print(\"\\t\\tPrediction (Training) Score:\\t{0:.2f}\".format(gb_clf.score(X_train, y_train)))\n",
    "        print(\"\\t\\tActual (Validation) Score:\\t{0:.2f}\".format(gb_clf.score(X_val, y_val)))\n",
    "\n",
    "        predicted = gb_clf.predict(X)\n",
    "        actual = y\n",
    "        assert len(predicted) == len(actual)\n",
    "        over_predict = 0\n",
    "        under_predict = 0\n",
    "        way_off = 0\n",
    "        for i in range(len(actual)):\n",
    "            p = predicted[i]\n",
    "            a = actual[i]\n",
    "            diff = a - p\n",
    "            if diff == 1:\n",
    "                under_predict += 1\n",
    "            if diff == -1:\n",
    "                over_predict += 1\n",
    "            if diff < -1 or diff > 1:\n",
    "                way_off += 1\n",
    "                # print('WAY off: predicted:', p, 'actual:', a)\n",
    "        under_pct = '{0:.2f}'.format(under_predict * 100.0 / len(actual))\n",
    "        over_pct = '{0:.2f}'.format(over_predict * 100.0 / len(actual))\n",
    "        way_pct = '{0:.2f}'.format(way_off * 100.0 / len(actual))\n",
    "        print('\\n\\t\\tPrediction Variance')\n",
    "        print('\\t\\t\\tPredicted less dangerous:', f'{under_pct}%')\n",
    "        print('\\t\\t\\tPredicted more dangerous:', f'{over_pct}%')\n",
    "        print('\\t\\t\\tWAY off:', f'{way_pct}%')\n",
    "\n",
    "    above_treeline = DATA.drop(['At Treeline', 'Below Treeline'], axis=1)\n",
    "    at_treeline = DATA.drop(['Above Treeline', 'Below Treeline'], axis=1)\n",
    "    below_treeline = DATA.drop(['Above Treeline', 'At Treeline'], axis=1)\n",
    "\n",
    "    print('Gradient Boosting Classifier Scores')\n",
    "    make_prediction_grad(above_treeline, 'Above Treeline')\n",
    "    make_prediction_grad(at_treeline, 'At Treeline')\n",
    "    make_prediction_grad(below_treeline, 'Below Treeline')\n",
    "\n",
    "gradient_boosting_prediction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
