{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, this code is not great.\n",
    "\n",
    "This code utilizes selenium, a webscraping tool, to pull archived\n",
    "avalanche danger reports. An alternative tool, BeautifulSoup, is \n",
    "NOT used because it only scrapes HTML data and not the JavaScript\n",
    "data that the Northwest Avalanche Center (NWAC) site uses for \n",
    "display. Selenium is a bit of a beast to work with unfortunately\n",
    "and if another tool is available we should at least look into it.\n",
    "\n",
    "This code opens and navigates to the NWAC archived avalanche reports\n",
    "site and pulls the links to individual avalanche reports. Then these\n",
    "pages are scraped to find danger ratings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the selenium webdriver to scrape the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def init_driver():\n",
    "    \"\"\"Initialize the web driver (essentially 'open the webpage')\"\"\"\n",
    "    # `snap install firefox`\n",
    "    # --- \n",
    "    # Set up the webdriver. \n",
    "    # This code will likely be different depending on the user's computer. \n",
    "    install_dir = \"/snap/firefox/current/usr/lib/firefox\"\n",
    "    driver_loc = os.path.join(install_dir, \"geckodriver\")\n",
    "    binary_loc = os.path.join(install_dir, \"firefox\")\n",
    "\n",
    "    service = Service(driver_loc)\n",
    "    opts = Options()\n",
    "    # opts.add_argument('-headless') # comment out for testing\n",
    "    opts.binary_location = binary_loc\n",
    "    # ---\n",
    "    driver = webdriver.Firefox(service=service, options=opts)\n",
    "    return driver\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some code to actually scrape the page. See associated video which verifies that the data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_danger_ratings(url):\n",
    "    # Make a new driver because reuse sometimes causes problems\n",
    "    driver = init_driver()\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    # Find all elements with the specified class name\n",
    "    res = driver.find_elements(By.CLASS_NAME, 'nac-dangerLabel')\n",
    "    print('actual:')\n",
    "    for danger in res:\n",
    "        if danger.text:\n",
    "            print('\\t'+danger.text)\n",
    "\n",
    "def test_danger_ratings(driver, url, expected):\n",
    "    print('expected:')\n",
    "    print(expected)\n",
    "    print_danger_ratings(url)\n",
    "\n",
    "\n",
    "\n",
    "def run_some_tests():\n",
    "    test_danger_ratings(driver, 'https://nwac.us/avalanche-forecast/#/forecast/6/124162', \\\n",
    "                        '\\tmoderate\\n\\tmoderate\\n\\tlow')\n",
    "    print('---')\n",
    "    test_danger_ratings(driver, 'https://nwac.us/avalanche-forecast/#/forecast/4/124286',\\\n",
    "                        '\\tconsiderable\\n\\tconsiderable\\n\\tmoderate')\n",
    "    print('---')\n",
    "    test_danger_ratings(driver, 'https://nwac.us/avalanche-forecast/#/forecast/4/123859',\\\n",
    "                        '\\thigh\\n\\thigh\\n\\tconsiderable')\n",
    "    print('---')\n",
    "    test_danger_ratings(driver, 'https://nwac.us/avalanche-forecast/#/forecast/2/123737',\\\n",
    "                        '\\tmoderate\\n\\tmoderate\\n\\tmoderate')\n",
    "    print('---')\n",
    "\n",
    "# driver = init_driver()\n",
    "# run_some_tests()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a bunch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the link to the report page\n",
    "# This is where selenium gets weird about navigating things...\n",
    "# See documentation for more info, but it's finding it my XML path\n",
    "\"\"\"\n",
    "page = driver.find_elements(By.XPATH, \"//a[contains(@href, '#/forecast/')]\")\n",
    "for p in page[15:20]:\n",
    "    print('link:', p.get_attribute('href'))\n",
    "    print_danger_ratings(p.get_attribute('href'))\n",
    "\"\"\"\n",
    "\n",
    "# todo: multiple pages\n",
    "\n",
    "\n",
    "\n",
    "def get_ratings_for_page(driver):\n",
    "\n",
    "    def print_report(driver):\n",
    "        # find the element that contains the archived reports\n",
    "        report_div = driver.find_element(By.CLASS_NAME, 'nac-forecast-archive')\n",
    "        table = report_div.find_element(By.CLASS_NAME, 'nac-html-table')\n",
    "        tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "        trs = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            td = tr.find_elements(By.TAG_NAME, 'td')\n",
    "            # \"parse\" table row data\n",
    "            date = td[0].find_element(By.TAG_NAME, 'a').text\n",
    "            location = td[3].text\n",
    "            danger = td[5].find_element(By.TAG_NAME, 'span').text\n",
    "            print(date, location, danger)\n",
    "\n",
    "    page_count = 15\n",
    "    \n",
    "    # NWAC Archived Avalanche Reports from the 22-23 season\n",
    "    # Provides daily danger predictions by area\n",
    "    archive = 'https://nwac.us/avalanche-forecast/#/archive/'\n",
    "    # \"Get\" the page\n",
    "    driver.get(archive)\n",
    "    # Wait for the page to load. There's probably a much better way to do this\n",
    "    time.sleep(4)\n",
    "\n",
    "    for i in range(page_count):\n",
    "        print_report(driver)\n",
    "        next_page_button = driver.find_elements(By.XPATH, \"//a[contains(text(), '>')]\")[0]\n",
    "        next_page_button.click()\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "driver = init_driver()\n",
    "\n",
    "get_ratings_for_page(driver)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What data do we actually need?\n",
    "- Date\n",
    "- Location\n",
    "- Danger Prediction\n",
    "    - Above, Near, Below Treeline - take max for now\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
